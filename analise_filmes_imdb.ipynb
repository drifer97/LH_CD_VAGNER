{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTxm6I0cs-uJ"
      },
      "outputs": [],
      "source": [
        "# Análise de Filmes IMDB: Do Dado ao Modelo de Predição\n",
        "\n",
        "Olá! Bem-vindo a esta análise do dataset de filmes do IMDB. Nosso objetivo é explorar esses dados para entender o que faz um filme ter sucesso e, no final, construir um modelo de \"inteligência artificial\" capaz de prever a nota de um filme.\n",
        "\n",
        "Vamos imaginar que somos cientistas de dados ajudando um estúdio de Hollywood!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passo 1: Arrumando a Casa (Limpeza dos Dados)\n",
        "\n",
        "Antes de qualquer análise, precisamos garantir que nossos dados estão \"limpos\". Isso significa que não há valores faltando, os tipos de dados estão corretos (números são números, texto é texto) e tudo está formatado direitinho.\n",
        "\n",
        "**Por que isso é importante?** Imagine tentar fazer uma conta de somar com uma palavra. Não dá, né? O computador precisa que os dados estejam no formato certo para trabalhar com eles."
      ],
      "metadata": {
        "id": "8LUlJtnJtO6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Primeiro, vamos importar as ferramentas que vamos usar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import pickle\n",
        "\n",
        "# Carregando nossos dados\n",
        "# Certifique-se de que o arquivo 'desafio_indicium_imdb.csv' está na mesma pasta\n",
        "df = pd.read_csv('desafio_indicium_imdb.csv')\n",
        "\n",
        "# Vamos dar uma espiadinha nos dados\n",
        "print(\"Cabeçalho dos dados:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nInformações sobre as colunas:\")\n",
        "df.info()"
      ],
      "metadata": {
        "id": "hPEfpJcOtV_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**O que encontramos?**\n",
        "* A coluna `Runtime` (duração) está como texto (\"175 min\") em vez de número.\n",
        "* A coluna `Gross` (faturamento) também está como texto e tem vírgulas.\n",
        "* Existem valores faltando (`NaN` ou `Null`) nas colunas `Certificate`, `Meta_score` e `Gross`.\n",
        "\n",
        "**Vamos limpar!**"
      ],
      "metadata": {
        "id": "5TqkE-0rtalO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Remover a coluna 'Unnamed: 0' que não serve pra nada\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "# 2. Transformar 'Runtime' em número\n",
        "df['Runtime'] = df['Runtime'].str.replace(' min', '').astype(int)\n",
        "\n",
        "# 3. Transformar 'Gross' em número\n",
        "df['Gross'] = df['Gross'].str.replace(',', '', regex=True)\n",
        "df['Gross'] = pd.to_numeric(df['Gross'], errors='coerce') # Se algo não virar número, vira NaN\n",
        "\n",
        "# 4. Lidando com valores faltando\n",
        "# Para notas e faturamento, vamos preencher com a média. Não é perfeito, mas é melhor que deixar em branco.\n",
        "df['Meta_score'].fillna(df['Meta_score'].mean(), inplace=True)\n",
        "df['Gross'].fillna(df['Gross'].mean(), inplace=True)\n",
        "# Para 'Certificate', vamos preencher com o mais comum (a moda)\n",
        "df['Certificate'].fillna(df['Certificate'].mode()[0], inplace=True)\n",
        "\n",
        "# 5. Corrigindo um erro que descobrimos depois: um ano que na verdade era \"PG\"\n",
        "df['Released_Year'] = pd.to_numeric(df['Released_Year'], errors='coerce')\n",
        "df.dropna(subset=['Released_Year'], inplace=True) # Removemos a linha com erro\n",
        "df['Released_Year'] = df['Released_Year'].astype(int)\n",
        "\n",
        "print(\"\\nDados limpinhos e prontos para a análise!\")\n",
        "df.info()"
      ],
      "metadata": {
        "id": "6Jq2iaMotd8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passo 2: O Detetive de Dados (Análise Exploratória - EDA)\n",
        "\n",
        "Agora que os dados estão organizados, vamos bancar os detetives. A Análise Exploratória (EDA) é o momento de fazer perguntas aos dados e ver o que eles respondem através de gráficos."
      ],
      "metadata": {
        "id": "Mqj5YxiMtgh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurações de estilo para os gráficos\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Gráfico 1: Distribuição das Variáveis Numéricas\n",
        "fig, axes = plt.subplots(3, 2, figsize=(15, 15))\n",
        "fig.suptitle('Distribuição das Variáveis Numéricas', fontsize=16)\n",
        "\n",
        "sns.histplot(df['IMDB_Rating'], kde=True, ax=axes[0, 0], color='skyblue').set_title('Distribuição da Nota IMDB')\n",
        "sns.histplot(df['Meta_score'], kde=True, ax=axes[0, 1], color='salmon').set_title('Distribuição do Meta Score')\n",
        "sns.histplot(df['Gross'] / 1e6, kde=True, ax=axes[1, 0], color='green').set(title='Distribuição do Faturamento (em Milhões)', xlabel='Faturamento (Milhões)')\n",
        "sns.histplot(df['Runtime'], kde=True, ax=axes[1, 1], color='gold').set_title('Distribuição da Duração (em Minutos)')\n",
        "sns.histplot(df['No_of_Votes'], kde=True, ax=axes[2, 0], color='purple').set_title('Distribuição do Número de Votos')\n",
        "fig.delaxes(axes[2, 1]) # Remove o subplot vazio\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CrL2JWhGtoMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico 2: Gêneros mais comuns\n",
        "plt.figure(figsize=(12, 8))\n",
        "# Separamos os gêneros que estão juntos na mesma linha (ex: \"Action, Drama\")\n",
        "genre_counts = df['Genre'].str.split(', ').explode().value_counts()\n",
        "sns.barplot(y=genre_counts.index, x=genre_counts.values, orient='h', palette='viridis')\n",
        "plt.title('Gêneros Mais Comuns no Dataset', fontsize=15)\n",
        "plt.xlabel('Número de Filmes')\n",
        "plt.ylabel('Gênero')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h6wA8GhMtrxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico 3: Matriz de Correlação\n",
        "plt.figure(figsize=(10, 8))\n",
        "numerical_cols = ['IMDB_Rating', 'Meta_score', 'Gross', 'Runtime', 'No_of_Votes']\n",
        "correlation_matrix = df[numerical_cols].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('O que está relacionado com o quê?', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mpL555pUtuRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight da Correlação**: O fator mais correlacionado com o Faturamento (`Gross`) é o Número de Votos (`No_of_Votes`). Isso sugere que a popularidade e o engajamento do público são cruciais para o sucesso financeiro de um filme!"
      ],
      "metadata": {
        "id": "aPdGaq_htw0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Análise de Texto: O que as Sinopses (`Overview`) nos Dizem?**\n",
        "\n",
        "Uma pergunta interessante é se podemos descobrir o gênero de um filme apenas lendo a sinopse. Para investigar isso, vamos usar uma técnica chamada **Nuvem de Palavras**, que cria uma imagem com as palavras mais frequentes em um texto. Se cada gênero tiver uma \"nuvem\" diferente, significa que eles usam vocabulários distintos!"
      ],
      "metadata": {
        "id": "hRrEpQw1FXPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos precisar da biblioteca wordcloud. Lembre-se que já a instalamos com o requirements.txt\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# Função para criar e mostrar uma nuvem de palavras para um gênero\n",
        "def gerar_nuvem_palavras(genero):\n",
        "    # Filtra o texto apenas dos filmes que contêm o gênero escolhido\n",
        "    texto = \" \".join(review for review in df[df['Genre'].str.contains(genero)].Overview)\n",
        "\n",
        "    # Cria a nuvem, ignorando palavras comuns em inglês (stopwords)\n",
        "    stopwords = set(STOPWORDS)\n",
        "    stopwords.update([\"film\", \"movie\", \"one\", \"story\", \"life\", \"new\", \"man\"]) # Adicionamos palavras comuns para limpar a nuvem\n",
        "    wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\", max_words=100).generate(texto)\n",
        "\n",
        "    # Mostra o gráfico\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f'Palavras Mais Comuns em Filmes de \"{genero}\"', fontsize=15)\n",
        "    plt.show()\n",
        "\n",
        "# Gerando a nuvem para os gêneros mais populares\n",
        "gerar_nuvem_palavras('Action')\n",
        "gerar_nuvem_palavras('Comedy')\n",
        "gerar_nuvem_palavras('Drama')"
      ],
      "metadata": {
        "id": "AOr9S5smFa7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passo 3: O Vidente (Construindo um Modelo de Machine Learning)\n",
        "\n",
        "Agora a parte mais legal! Vamos usar o que aprendemos para treinar um modelo de Machine Learning. O objetivo é que ele aprenda os padrões dos dados para conseguir **prever a nota IMDB** de um filme que ele nunca viu antes."
      ],
      "metadata": {
        "id": "njT3jya1ty_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1. Definir as colunas que vamos usar para prever (features) e a coluna que queremos prever (target)\n",
        "features = ['Meta_score', 'No_of_Votes', 'Gross', 'Runtime', 'Genre', 'Director', 'Star1']\n",
        "target = 'IMDB_Rating'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# 2. Dividir os dados em um conjunto para treinar e outro para testar o modelo\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Criar um \"pipeline\" de pré-processamento\n",
        "# Isso vai transformar as colunas de texto (como Gênero e Diretor) em números que o modelo entende\n",
        "categorical_features = ['Genre', 'Director', 'Star1']\n",
        "numerical_features = ['Meta_score', 'No_of_Votes', 'Gross', 'Runtime']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', 'passthrough', numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
        "\n",
        "# 4. Definir o modelo que vamos usar\n",
        "# Random Forest é como um comitê de \"árvores de decisão\" que votam no resultado final\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "# 5. Juntar tudo em um Pipeline final\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('regressor', model)])\n",
        "\n",
        "# 6. Treinar o modelo!\n",
        "print(\"Treinando o modelo...\")\n",
        "pipeline.fit(X_train, y_train)\n",
        "print(\"Modelo treinado com sucesso!\")"
      ],
      "metadata": {
        "id": "T4D8fTfjt1vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passo 4: Testando o Vidente"
      ],
      "metadata": {
        "id": "wEjW3nIrt4p5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliando o modelo com os dados de teste\n",
        "y_pred = pipeline.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f\"O erro médio do nosso modelo é de: {rmse:.4f} pontos na nota IMDB.\")\n",
        "\n",
        "# Fazendo uma previsão para um filme específico\n",
        "new_movie_data = {\n",
        "    'Meta_score': 80.0,\n",
        "    'No_of_Votes': 2343110,\n",
        "    'Gross': 28341469.0,\n",
        "    'Runtime': 142,\n",
        "    'Genre': 'Drama',\n",
        "    'Director': 'Frank Darabont',\n",
        "    'Star1': 'Tim Robbins',\n",
        "}\n",
        "\n",
        "new_movie_df = pd.DataFrame([new_movie_data])\n",
        "predicted_rating = pipeline.predict(new_movie_df)\n",
        "\n",
        "print(f\"\\nPrevisão para 'The Shawshank Redemption':\")\n",
        "print(f\"Nota IMDB Prevista: {predicted_rating[0]:.2f}\")"
      ],
      "metadata": {
        "id": "ADV54RTvt7OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passo 5: Empacotando o Modelo\n",
        "\n",
        "Finalmente, salvamos nosso modelo treinado em um arquivo `.pkl`. Isso nos permite usar o modelo no futuro sem ter que treiná-lo de novo toda vez."
      ],
      "metadata": {
        "id": "SW-QduPot9mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o pipeline completo (pré-processador + modelo)\n",
        "with open('imdb_rating_predictor.pkl', 'wb') as f:\n",
        "    pickle.dump(pipeline, f)\n",
        "\n",
        "print(\"\\nModelo salvo com sucesso no arquivo 'imdb_rating_predictor.pkl'\")"
      ],
      "metadata": {
        "id": "7gxQ47FWt_oP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}